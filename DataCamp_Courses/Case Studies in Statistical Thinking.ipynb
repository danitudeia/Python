{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80f05a7-a104-4948-8390-616dd9f1deb1",
   "metadata": {},
   "source": [
    "### EDA: Plot ECDFs of active bout length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e00e60-f0eb-4c82-aaa6-9d8ed9e2479e",
   "metadata": {},
   "source": [
    "##### Import the module dc_stat_think as dcst so you have its functions available.\n",
    "##### Generate the x and y values for plotting the ECDF of the wild type fish (bout_lengths_wt) using dcst.ecdf(). Store the result in numpy arrays named x_wt and y_wt.\n",
    "##### Do the same for the the mutant fish (bout_lengths_mut), storing the result in numpy arrays named x_mut and y_mut.\n",
    "##### Use plt.plot() to plot the two ECDFs as dots on the same plot. Be sure to specify the keyword arguments marker='.' and linestyle='none'.\n",
    "##### Show your plot using plt.show()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65ae1e-ae6e-4f74-8127-b18b3016a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dc_stat_think module as dcst\n",
    "import dc_stat_think as dcst\n",
    "\n",
    "# Generate x and y values for plotting ECDFs\n",
    "x_wt, y_wt = dcst.ecdf(bout_lengths_wt)\n",
    "x_mut, y_mut = dcst.ecdf(bout_lengths_mut)\n",
    "\n",
    "# Plot the ECDFs\n",
    "_ = plt.plot(x_wt, y_wt, marker='.', linestyle='none')\n",
    "_ = plt.plot(x_mut, y_mut, marker='.', linestyle='none')\n",
    "\n",
    "# Make a legend, label axes, and show plot\n",
    "_ = plt.legend(('wt', 'mut'))\n",
    "_ = plt.xlabel('active bout length (min)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941db7e-c569-4efe-8b12-c84c0d35bbdf",
   "metadata": {},
   "source": [
    "### Parameter estimation: active bout length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86e583-848e-4021-9542-7b130d513e75",
   "metadata": {},
   "source": [
    "##### Compute the mean active bout length for wild type and mutant using np.mean(). Store the results as mean_wt and mean_mut.\n",
    "##### Draw 10,000 bootstrap replicates for each using dcst.draw_bs_reps(), storing the results as bs_reps_wt and bs_reps_mut.\n",
    "##### Compute a 95% confidence interval from the bootstrap replicates using np.percentile(), storing the results as conf_int_wt and conf_int_mut.\n",
    "##### Print the mean and confidence intervals to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106832b-e90d-40b8-be2e-085c7ea76472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean active bout length\n",
    "mean_wt = np.mean(bout_lengths_wt)\n",
    "mean_mut = np.mean(bout_lengths_mut)\n",
    "\n",
    "# Draw bootstrap replicates\n",
    "bs_reps_wt = dcst.draw_bs_reps(bout_lengths_wt, np.mean, size=10000)\n",
    "bs_reps_mut = dcst.draw_bs_reps(bout_lengths_mut, np.mean, size=10000)\n",
    "\n",
    "# Compute 95% confidence intervals\n",
    "conf_int_wt = np.percentile(bs_reps_wt, [2.5, 97.5])\n",
    "conf_int_mut = np.percentile(bs_reps_mut, [2.5, 97.5])\n",
    "\n",
    "# Print the results\n",
    "print(\"\"\"\n",
    "wt:  mean = {0:.3f} min., conf. int. = [{1:.1f}, {2:.1f}] min.\n",
    "mut: mean = {3:.3f} min., conf. int. = [{4:.1f}, {5:.1f}] min.\n",
    "\"\"\".format(mean_wt, *conf_int_wt, mean_mut, *conf_int_mut))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ebc83d-2ebe-414a-b4a4-9adc09c608db",
   "metadata": {},
   "source": [
    "### Permutation test: wild type versus heterozygote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa02567-9000-498e-a5e1-13e4c2ac4915",
   "metadata": {},
   "source": [
    "##### Compute the difference of means (heterozygote minus wild type bout lengths) of the actual datasets, storing the result in the variable diff_means_exp. The numpy arrays bout_lengths_wt and bout_lengths_het are already in your namespace.\n",
    "##### Draw 10,000 permutation replicates of the difference of means using dcst.draw_perm_reps(). You can use the dcst.diff_of_means() function as well, storing your result in perm_reps.\n",
    "##### Compute the p-value, defining \"at least as extreme as\" to be that the difference of means under the null hypothesis is greater than or equal to that which was observed experimentally.\n",
    "##### Print the p-value to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12633f4f-49c4-4b8b-8bf8-41866cb16edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference of means: diff_means_exp\n",
    "diff_means_exp = np.mean(bout_lengths_het) - np.mean(bout_lengths_wt)\n",
    "\n",
    "# Draw permutation replicates: perm_reps\n",
    "perm_reps = dcst.draw_perm_reps(bout_lengths_het,bout_lengths_wt,\n",
    "                               dcst.diff_of_means, size=10000)\n",
    "\n",
    "# Compute the p-value: p-val\n",
    "p_val = np.sum(perm_reps >= diff_means_exp) / len(perm_reps)\n",
    "\n",
    "# Print the result\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2c0a5-71eb-4d50-b02f-0a6be1d2b5c3",
   "metadata": {},
   "source": [
    "### Bootstrap hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80266e7-64e4-41e1-9eaf-8c38c29c0d6a",
   "metadata": {},
   "source": [
    "##### Make an array, bout_lengths_concat, that contains all of the bout lengths for both wild type (bout_lengths_wt) and heterozygote (bout_lengths_het) using np.concatenate().\n",
    "##### Compute the mean of all bout lengths from this concatenated array (bout_lengths_concat), storing the results in the variable mean_bout_length.\n",
    "##### Shift both datasets such that they both have the same mean, namely mean_bout_length. Store the shifted arrays in variables wt_shifted and het_shifted.\n",
    "##### Use dcst.draw_bs_reps() to draw 10,000 bootstrap replicates of the mean for each of the shifted datasets. Store the respective replicates in bs_reps_wt and bs_reps_het.\n",
    "##### Subtract bs_reps_wt from bs_reps_het to get the bootstrap replicates of the difference of means. Store the results in the variable bs_reps.\n",
    "##### Compute the p-value, defining \"at least as extreme as\" to be that the difference of means under the null hypothesis is greater than or equal to that which was observed experimentally. The variable diff_means_exp from the last exercise is already in your namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1592781-271f-4ef8-afcb-db58b469caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate arrays: bout_lengths_concat\n",
    "bout_lengths_concat = np.concatenate((bout_lengths_wt, bout_lengths_het))\n",
    "\n",
    "# Compute mean of all bout_lengths: mean_bout_length\n",
    "mean_bout_length = np.mean(bout_lengths_concat)\n",
    "\n",
    "# Generate shifted arrays\n",
    "wt_shifted = bout_lengths_wt - np.mean(bout_lengths_wt) + mean_bout_length\n",
    "het_shifted = bout_lengths_het - np.mean(bout_lengths_het) + mean_bout_length\n",
    "\n",
    "# Compute 10,000 bootstrap replicates from shifted arrays\n",
    "bs_reps_wt = dcst.draw_bs_reps(wt_shifted, np.mean, size=10000)\n",
    "bs_reps_het = dcst.draw_bs_reps(het_shifted, np.mean, size=10000)\n",
    "\n",
    "# Get replicates of difference of means: bs_reps\n",
    "bs_reps = bs_reps_het - bs_reps_wt\n",
    "\n",
    "# Compute and print p-value: p\n",
    "p = np.sum(bs_reps >= diff_means_exp) / len(bs_reps)\n",
    "print('p-value =', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e103588-c89d-4e2c-922b-a3a4687e312b",
   "metadata": {},
   "source": [
    "### Assessing the growth rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e135818-9105-4f95-af61-802cbfedab23",
   "metadata": {},
   "source": [
    "##### Compute the logarithm of the bacterial area (bac_area) using np.log() and store the result in the variable log_bac_area.\n",
    "##### Compute the slope and intercept of the semilog growth curve using np.polyfit(). Store the slope in the variable growth_rate and the intercept in log_a0.\n",
    "##### Draw 10,000 pairs bootstrap replicates of the growth rate and log initial area using dcst.draw_bs_pairs_linreg(). Store the results in growth_rate_bs_reps and log_a0_bs_reps.\n",
    "##### Use np.percentile() to compute the 95% confidence interval of the growth rate (growth_rate_bs_reps).\n",
    "##### Print the growth rate and confidence interval to the screen. This has been done for you, so hit 'Submit Answer' to view the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae208cf6-26c9-49a2-aed0-7e8611635073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute logarithm of the bacterial area: log_bac_area\n",
    "log_bac_area = np.log(bac_area)\n",
    " \n",
    "# Compute the slope and intercept: growth_rate, log_a0\n",
    "growth_rate, log_a0 = np.polyfit(t, log_bac_area, 1)\n",
    " \n",
    "# Draw 10,000 pairs bootstrap replicates: growth_rate_bs_reps, log_a0_bs_reps\n",
    "growth_rate_bs_reps, log_a0_bs_reps = \\\n",
    "            dcst.draw_bs_pairs_linreg(t, log_bac_area, size=10000)\n",
    "     \n",
    "# Compute confidence intervals: growth_rate_conf_int\n",
    "growth_rate_conf_int = np.percentile(growth_rate_bs_reps, [2.5, 97.5])\n",
    "\n",
    "# Print the result to the screen\n",
    "print(\"\"\"\n",
    "Growth rate: {0:.4f} 1/hour\n",
    "95% conf int: [{1:.4f}, {2:.4f}] 1/hour\n",
    "\"\"\".format(growth_rate, *growth_rate_conf_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009949c-b320-40dd-8a3c-d4c83293f056",
   "metadata": {},
   "source": [
    "### Plotting the growth curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a22af80-572b-482c-a723-69dc66399377",
   "metadata": {},
   "source": [
    "##### Plot the data points using plt.semilogy(). The numpy arrays t and bac_area are again in your namespace.\n",
    "##### Use np.array() to generate time values for plotting the bootstrap lines. Call this t_bs. The time should go from 0 to 14 hours.\n",
    "##### Write a for loop to plot regression lines corresponding to the first 100 pairs bootstrap replicates. The numpy arrays growth_rate_bs_reps and log_a0_bs_reps that you computed in the last exercise are in your namespace.\n",
    "##### Compute the growth curve by exponentiating the linear regression line using np.exp().\n",
    "##### Plot the theoretical line using plt.semilogy() with keyword arguments linewidth=0.5, alpha=0.05, and color='red'.\n",
    "##### Label the axes and show your plot. Appropriate labels for the respective x and y axes are 'time (hr)' and 'area (sq. µm)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47540cb-967d-4e61-b42e-2d4e95af05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points in a semilog-y plot with axis labeles\n",
    "_ = plt.semilogy(t, bac_area, marker='.', linestyle='none')\n",
    " \n",
    "# Generate x-values for the bootstrap lines: t_bs\n",
    "t_bs = np.array([0, 14])\n",
    " \n",
    "# Plot the first 100 bootstrap lines\n",
    "for i in range(100):\n",
    "    y = np.exp(growth_rate_bs_reps[i] * t_bs + log_a0_bs_reps[i])\n",
    "    _ = plt.semilogy(t_bs, y, linewidth=0.5, alpha=0.05, color='red')\n",
    "     \n",
    "# Label axes and show plot\n",
    "_ = plt.xlabel('time (hr)')\n",
    "_ = plt.ylabel('area (sq. µm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a5bfb-be37-40d0-b17c-f00898bb698c",
   "metadata": {},
   "source": [
    "### Graphical EDA of men's 200 free heats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb1d4fc-5372-4d93-9406-c9a260123a33",
   "metadata": {},
   "source": [
    "##### Generate x and y values for the ECDF using dcst.ecdf(). The swim times of the heats are stored in the numpy array mens_200_free_heats.\n",
    "##### Plot the ECDF as dots. Remember to specify the appropriate marker and linestyle.\n",
    "##### Label the axes and show the plot. Use 'time (s)' as the x-axis label and 'ECDF' as the y-axis label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c084d190-42c6-4e53-9559-7ab16be68713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x and y values for ECDF: x, y\n",
    "x, y = dcst.ecdf(mens_200_free_heats)\n",
    "\n",
    "# Plot the ECDF as dots\n",
    "plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "# Label axes and show plot\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1e0b0-6bdf-4de4-9916-a65766ea18b9",
   "metadata": {},
   "source": [
    "### 200 m free time with confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ee5d1-94f3-41ce-9d32-1486583a734e",
   "metadata": {},
   "source": [
    "##### Compute the mean and median swim times, storing them in variables mean_time and median_time. The swim times are contained in mens_200_free_heats.\n",
    "##### Draw 10,000 bootstrap replicates each of the mean and median swim time using dcst.draw_bs_reps(). Store the results in bs_reps_mean and bs_reps_median.\n",
    "##### Compute the 95% confidence intervals for the mean and median using the bootstrap replicates and np.percentile().\n",
    "##### Hit 'Submit Answer' to print the results to the screen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f54654-6ed0-479e-a84e-49eea1c6e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and median swim times\n",
    "mean_time = np.mean(mens_200_free_heats)\n",
    "median_time = np.median(mens_200_free_heats)\n",
    "\n",
    "# Draw 10,000 bootstrap replicates of the mean and median\n",
    "bs_reps_mean = dcst.draw_bs_reps(mens_200_free_heats, np.mean, size =10000)\n",
    "bs_reps_median = dcst.draw_bs_reps(mens_200_free_heats, np.median, size =10000)\n",
    "\n",
    "\n",
    "# Compute the 95% confidence intervals\n",
    "conf_int_mean = np.percentile(bs_reps_mean, [2.5, 97.5])\n",
    "conf_int_median = np.percentile(bs_reps_median, [2.5, 97.5])\n",
    "\n",
    "# Print the result to the screen\n",
    "print(\"\"\"\n",
    "mean time: {0:.2f} sec.\n",
    "95% conf int of mean: [{1:.2f}, {2:.2f}] sec.\n",
    "\n",
    "median time: {3:.2f} sec.\n",
    "95% conf int of median: [{4:.2f}, {5:.2f}] sec.\n",
    "\"\"\".format(mean_time, *conf_int_mean, median_time, *conf_int_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda348f3-10eb-436d-a94b-e4beff45a1a8",
   "metadata": {},
   "source": [
    "### EDA: finals versus semifinals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d6c49-7e1c-47fb-8776-ed8f76976a84",
   "metadata": {},
   "source": [
    "##### Compute the fractional improvement from the semifinals to finals. Store the results as f.\n",
    "##### Compute the x and y values for plotting the ECDF.\n",
    "##### Plot the ECDF as dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd08da2-4c03-42ad-a5e1-56df5a43ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute fractional difference in time between finals and semis\n",
    "f = (semi_times - final_times) / semi_times\n",
    "\n",
    "# Generate x and y values for the ECDF: x, y\n",
    "x, y = dcst.ecdf(f)\n",
    "\n",
    "# Make a plot of the ECDF\n",
    "plt.plot(x, y, marker='.', linestyle='none')\n",
    "\n",
    "# Label axes and show plot\n",
    "_ = plt.xlabel('f')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0042d-e78a-4379-970a-4de46f53bf9d",
   "metadata": {},
   "source": [
    "### Parameter estimates of difference between finals and semifinals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5272f-1c10-4a46-885e-e8234ef9db72",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Compute the mean of f, storing the result in f_mean.\n",
    "##### Generate 10,000 bootstrap replicates of the mean of f. Store the results in bs_reps.\n",
    "##### Compute a 95% confidence interval from these bootstrap replicates.\n",
    "##### Hit 'Submit Answer' to print the mean and confidence interval to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0735e-1ea7-4b43-a6e9-e02c0922e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean fractional time difference: f_mean\n",
    "f_mean = np.mean(f)\n",
    " \n",
    "# Get bootstrap reps of mean: bs_reps\n",
    "bs_reps = dcst.draw_bs_reps(f, func=np.mean, size=10000)\n",
    " \n",
    "# Compute confidence intervals: conf_int\n",
    "conf_int = np.percentile(bs_reps, [2.5, 97.5])\n",
    "\n",
    "# Report\n",
    "print(\"\"\"\n",
    "mean frac. diff.: {0:.5f}\n",
    "95% conf int of mean frac. diff.: [{1:.5f}, {2:.5f}]\"\"\".format(f_mean, *conf_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd331ffa-4c8d-4450-a620-b97fa0736702",
   "metadata": {},
   "source": [
    "### Generating permutation samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eede58-86fc-4740-bd54-dcfd010597ea",
   "metadata": {},
   "source": [
    "##### Define a function with signature swap_random(a, b) that does the following.\n",
    "##### Create an array swap_inds the same length as the input arrays where each entry is True with 50/50 probability. Hint: Use np.random.random() with the size=len(a) keyword argument. Each entry in the result that is less than 0.5 should be True.\n",
    "##### Make copies of a and b, called a_out and b_out, respectively using np.copy().\n",
    "##### Use Boolean indexing with the swap_inds array to swap the appropriate entries of b into a_out and of a into b_out.\n",
    "##### Return a_out and b_out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb496d-d693-4cd4-a6ce-84d1a4bda0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_random(a, b):\n",
    "    \"\"\"Randomly swap entries in two arrays.\"\"\"\n",
    "    # Indices to swap\n",
    "    swap_inds = np.random.random(size=len(a)) < 0.5\n",
    "     \n",
    "    # Make copies of arrays a and b for output\n",
    "    a_out = np.copy(a)\n",
    "    b_out = np.copy(b)\n",
    "     \n",
    "    # Swap values\n",
    "    a_out[swap_inds] = b[swap_inds]\n",
    "    b_out[swap_inds] = a[swap_inds]\n",
    " \n",
    "    return a_out, b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b760151-2672-4e10-8e28-975bc7ee3757",
   "metadata": {},
   "source": [
    "### Hypothesis test: Do women swim the same way in semis and finals?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0b854-c8c1-4466-9ccf-8e74e0737f79",
   "metadata": {},
   "source": [
    "###### Set up an empty array to contain 1000 permutation replicates using np.empty(). Call this array perm_reps.\n",
    "######  a for loop to generate permutation replicates.\n",
    "###### Generate a permutation sample using the swap_random() function you just wrote. Store the arrays in semi_perm and final_perm.\n",
    "###### Compute the value of f from the permutation sample.\n",
    "###### Store the mean of the permutation sample in the perm_reps array.\n",
    "###### Compute the p-value and print it to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfa9d9-6f3c-44c1-9d2f-a2c200b053c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up array of permutation replicates\n",
    "perm_reps = np.empty(1000)\n",
    " \n",
    "for i in range(1000):\n",
    "    # Generate a permutation sample\n",
    "    semi_perm, final_perm = swap_random(semi_times, final_times)\n",
    "     \n",
    "    # Compute f from the permutation sample\n",
    "    f = (semi_perm - final_perm) / semi_perm\n",
    "     \n",
    "    # Compute and store permutation replicate\n",
    "    perm_reps[i] = np.mean(f)\n",
    " \n",
    "# Compute and print p-value\n",
    "print('p =', np.sum(perm_reps >= f_mean) / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75ef2c-e5dc-4794-b6bb-ab0d2d066bf3",
   "metadata": {},
   "source": [
    "### EDA: Plot all your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ceb19-2a0c-4973-98c8-a1a7045fceb5",
   "metadata": {},
   "source": [
    "##### Write a for loop, looping over the set of splits for each swimmer to:\n",
    "##### Plot the split time versus split number. Use the linewidth=1 and color='lightgray' keyword arguments.\n",
    "##### Compute the mean split times for each distance. You can do this using the np.mean() function with the axis=0 keyword argument. This tells np.mean() to compute the means over rows, which will give the mean split time for each split number.\n",
    "##### Plot the mean split times (y-axis) versus split number (x-axis) using the marker='.', linewidth=3, and markersize=12 keyword arguments.\n",
    "##### Label the axes and show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac722b40-15af-4348-812c-51936f797189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the splits for each swimmer\n",
    "for splitset in splits:\n",
    "    _ = plt.plot(split_number, splitset, linewidth=1, color='lightgray')\n",
    " \n",
    "# Compute the mean split times\n",
    "mean_splits = np.mean(splits, axis=0)\n",
    " \n",
    "# Plot the mean split times\n",
    "_ = plt.plot(split_number, mean_splits, linewidth=3, markersize=12)\n",
    " \n",
    "# Label axes and show plot\n",
    "_ = plt.xlabel('split number')\n",
    "_ = plt.ylabel('split time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddfde9-b11d-48af-82b4-92afa17b502d",
   "metadata": {},
   "source": [
    "### Linear regression of average split time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c71c3-2b3a-4e85-889b-2ebcb0c7d8bf",
   "metadata": {},
   "source": [
    "##### Use np.polyfit() to perform a linear regression to get the slowdown per split. The variables split_number and mean_splits are already in your namespace. Store the slope and interecept respectively in slowdown and split_3.\n",
    "##### Use dcst.draw_bs_pairs_linreg() to compute 10,000 pairs bootstrap replicates of the slowdown per split. Store the result in bs_reps. The bootstrap replicates of the intercept are not relevant for this analysis, so you can store them in the throwaway variable _.\n",
    "##### Compute the 95% confidence interval of the slowdown per split.\n",
    "##### Plot the split number (split_number) versus the mean split time (mean_splits) as dots, along with the best-fit line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b019bc-ce43-4653-871c-866022837d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform regression\n",
    "slowdown, split_3 = np.polyfit(split_number, mean_splits, deg=1)\n",
    " \n",
    "# Compute pairs bootstrap\n",
    "bs_reps, _ = dcst.draw_bs_pairs_linreg(split_number, mean_splits, size=10000)\n",
    " \n",
    "# Compute confidence interval\n",
    "conf_int = np.percentile(bs_reps, [2.5, 97.5])\n",
    " \n",
    "# Plot the data with regressions line\n",
    "_ = plt.plot(split_number, mean_splits, marker='.', linestyle='none')\n",
    "_ = plt.plot(split_number, slowdown * split_number + split_3, '-')\n",
    " \n",
    "# Label axes and show plot\n",
    "_ = plt.xlabel('split number')\n",
    "_ = plt.ylabel('split time (s)')\n",
    "plt.show()\n",
    " \n",
    "\n",
    "# Print the slowdown per split\n",
    "print(\"\"\"\n",
    "mean slowdown: {0:.3f} sec./split\n",
    "95% conf int of mean slowdown: [{1:.3f}, {2:.3f}] sec./split\"\"\".format(\n",
    "    slowdown, *conf_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c03ff-2e70-4c55-b0b6-42f8fab62392",
   "metadata": {},
   "source": [
    "### Hypothesis test: are they slowing down?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2850a97-2131-4a1d-9ec8-2c9ee14c7d25",
   "metadata": {},
   "source": [
    "##### Compute the observed Pearson correlation, storing it as rho.\n",
    "##### Using np.empty(), initialize the array of 10,000 permutation replicates of the Pearson correlation, naming it perm_reps_rho.\n",
    "##### Write a for loop to:\n",
    "##### Scramble the split number array using np.random.permutation(), naming it scrambled_split_number.\n",
    "##### Compute the Pearson correlation coefficient between the scrambled split number array and the mean split times and store it in perm_reps_rho.\n",
    "##### Compute the p-value and display it on the screen. Take \"at least as extreme as\" to mean that the Pearson correlation is at least as big as was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968431c-d4d6-4757-a832-770323739825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed correlation\n",
    "rho = dcst.pearson_r(split_number, mean_splits)\n",
    " \n",
    "# Initialize permutation reps\n",
    "perm_reps_rho = np.empty(10000)\n",
    " \n",
    "# Make permutation reps\n",
    "for i in range(10000):\n",
    "    # Scramble the split number array\n",
    "    scrambled_split_number = np.random.permutation(split_number)\n",
    "     \n",
    "    # Compute the Pearson correlation coefficient\n",
    "    perm_reps_rho[i] = dcst.pearson_r(scrambled_split_number, mean_splits)\n",
    "     \n",
    "# Compute and print p-value\n",
    "p_val = np.sum(perm_reps_rho >= rho) / len(perm_reps_rho)\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a9334-1a36-4d28-b586-07c8b16fb206",
   "metadata": {},
   "source": [
    "### ECDF of improvement from low to high lanes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08a085-710d-4b43-bd4a-f603737b617b",
   "metadata": {},
   "source": [
    "##### Compute the fractional improvement for being in a high-numbered lane for each swimmer using the formula from the last exercise. Store the result in the variable f.\n",
    "##### Compute the x and y values for plotting the ECDF.\n",
    "##### Plot the ECDF as dots.\n",
    "##### Label the x-axis 'f', y-axis 'ECDF', and show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a8c81-4c8c-4fcb-a901-8df56d6caa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fractional improvement of being in high lane: f\n",
    "f = (swimtime_low_lanes - swimtime_high_lanes) / swimtime_low_lanes\n",
    " \n",
    "# Make x and y values for ECDF: x, y\n",
    "x, y = dcst.ecdf(f)\n",
    " \n",
    "# Plot the ECDFs as dots\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    " \n",
    "# Label the axes and show the plot\n",
    "_ = plt.xlabel('f')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa515140-6372-4f5a-9140-69d2c03fe0df",
   "metadata": {},
   "source": [
    "### Estimation of mean improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1e031f-ae47-4a9c-959e-0ce6e8b71d1a",
   "metadata": {},
   "source": [
    "##### Compute the mean fractional difference using np.mean(). The variable f from the last exercise is already in your namespace.\n",
    "##### Draw 10,000 bootstrap replicates of the mean fractional difference using dcst.draw_bs_reps(). Store the result in a numpy array named bs_reps.\n",
    "##### Compute the 95% confidence interval using np.percentile().\n",
    "##### Hit 'Submit Answer' to print the mean fractional improvement and 95% confidence interval to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba382c-4cf1-4803-b5d7-fa46e039e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean difference: f_mean\n",
    "f_mean = np.mean(f)\n",
    " \n",
    "# Draw 10,000 bootstrap replicates: bs_reps\n",
    "bs_reps = dcst.draw_bs_reps(f, np.mean, size=10000)\n",
    " \n",
    "# Compute 95% confidence interval: conf_int\n",
    "conf_int = np.percentile(bs_reps, [2.5, 97.5])\n",
    "\n",
    "# Print the result\n",
    "print(\"\"\"\n",
    "mean frac. diff.: {0:.5f}\n",
    "95% conf int of mean frac. diff.: [{1:.5f}, {2:.5f}]\"\"\".format(f_mean, *conf_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7287882-75c7-477a-b5cb-52d42823482b",
   "metadata": {},
   "source": [
    "### Hypothesis test: Does lane assignment affect performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24a4309-d42b-4f98-a463-f06a2e0e2707",
   "metadata": {},
   "source": [
    "##### Create an array f_shift, by shifting f such that its mean is zero. You can use the variable f_mean computed in previous exercises.\n",
    "##### Draw 100,000 bootstrap replicates of the mean of the f_shift.\n",
    "##### Compute and print the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f6dc0-9505-447e-8b92-8c0b23f295ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift f: f_shift\n",
    "f_shift = f - f_mean\n",
    " \n",
    "# Draw 100,000 bootstrap replicates of the mean: bs_reps\n",
    "bs_reps = dcst.draw_bs_reps(f_shift, np.mean, size=100000)\n",
    " \n",
    "# Compute and report the p-value\n",
    "p_val = np.sum(bs_reps >= f_mean) / 100000\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1aec4-62bd-467a-b059-31418ab7b630",
   "metadata": {},
   "source": [
    "### Did the 2015 event have this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a4713b-27c5-4fc6-beb3-38f0c27281cf",
   "metadata": {},
   "source": [
    "##### Compute the fractional improvement, f using the arrays swimtime_low_lanes_15 and swimtime_high_lanes_15. Also compute the mean of f, storing it as f_mean.\n",
    "##### Draw 10,000 bootstrap replicates of the mean f.\n",
    "##### Compute the 95% confidence interval of the mean fractional improvement.\n",
    "##### Shift f to create f_shift such that its mean is zero.\n",
    "##### Draw 100,000 bootstrap replicates of the mean of f_shift.\n",
    "##### Compute the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d89dcf-2710-46bd-9f74-95fa9856c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute f and its mean\n",
    "f = (swimtime_low_lanes_15 - swimtime_high_lanes_15) / swimtime_low_lanes_15\n",
    "f_mean = np.mean(f)\n",
    " \n",
    "# Draw 10,000 bootstrap replicates\n",
    "bs_reps = dcst.draw_bs_reps(f, np.mean, size=10000)\n",
    " \n",
    "# Compute 95% confidence interval\n",
    "conf_int = np.percentile(bs_reps, [2.5, 97.5])\n",
    " \n",
    "# Shift f\n",
    "f_shift = f - f_mean\n",
    " \n",
    "# Draw 100,000 bootstrap replicates of the mean\n",
    "bs_reps = dcst.draw_bs_reps(f_shift, np.mean, size=100000)\n",
    " \n",
    "# Compute the p-value\n",
    "p_val = np.sum(bs_reps >= f_mean) / 100000\n",
    "\n",
    "# Print the results\n",
    "print(\"\"\"\n",
    "mean frac. diff.: {0:.5f}\n",
    "95% conf int of mean frac. diff.: [{1:.5f}, {2:.5f}]\n",
    "p-value: {3:.5f}\"\"\".format(f_mean, *conf_int, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1742345-aab2-4514-9f93-ecd73f28c125",
   "metadata": {},
   "source": [
    "### EDA: mean differences between odd and even splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c540b1d7-924e-44b3-bb06-023437aac426",
   "metadata": {},
   "source": [
    "##### Plot f_13 versus lanes using keyword arguments marker='.', markersize=12, and linestyle='none'.\n",
    "##### Do the same for f_15 versus lanes.\n",
    "##### Label the x-axis 'lane', y-axis 'frac. diff. (odd - even)', and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca8ae6-437b-4166-af0c-7418e011af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the the fractional difference for 2013 and 2015\n",
    "plt.plot(lanes, f_13, marker='.', markersize=12, linestyle='none')\n",
    "plt.plot(lanes, f_15, marker='.', markersize=12, linestyle='none')\n",
    " \n",
    "# Add a legend\n",
    "_ = plt.legend((2013, 2015))\n",
    " \n",
    "# Label axes and show plot\n",
    "plt.xlabel('lane')\n",
    "plt.ylabel('frac. diff. (odd - even)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce57bf-fb36-4956-b68d-5b1d88c39d3c",
   "metadata": {},
   "source": [
    "### How does the current effect depend on lane position?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3887fa-7569-45d2-aecd-c765258fc4ca",
   "metadata": {},
   "source": [
    "##### Compute the slope and intercept of the f_13 versus lanes line using np.polyfit().\n",
    "##### Use dcst.draw_bs_pairs_linreg() to get 10,000 bootstrap replicates of the slope and intercept, storing them respectively in bs_reps_slope and bs_reps_int.\n",
    "##### Use the bootstrap replicates to compute a 95% confidence interval for the slope.\n",
    "##### Print the slope and 95% confidence interval to the screen. This has been done for you.\n",
    "##### Using np.array(), generate x-values to use for the plot of the bootstrap lines. x should go from 1 to 8.\n",
    "##### The plot is already populated with the data. Write a for loop to add 100 bootstrap lines to the plot using the keyword arguments color='red', alpha=0.2, and linewidth=0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b6604-0d02-448a-a046-dd45270b165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the slope and intercept of the frac diff/lane curve\n",
    "slope, intercept  = np.polyfit(lanes, f_13, 1)\n",
    " \n",
    "# Compute bootstrap replicates\n",
    "bs_reps_slope, bs_reps_int = dcst.draw_bs_pairs_linreg(lanes, f_13, size=10000)\n",
    " \n",
    "# Compute 95% confidence interval of slope\n",
    "conf_int = np.percentile(bs_reps_slope, [2.5, 97.5])\n",
    "\n",
    "# Print slope and confidence interval\n",
    "print(\"\"\"\n",
    "slope: {0:.5f} per lane\n",
    "95% conf int: [{1:.5f}, {2:.5f}] per lane\"\"\".format(slope, *conf_int))\n",
    "\n",
    "# x-values for plotting regression lines\n",
    "x = np.array([1, 8])\n",
    " \n",
    "# Plot 100 bootstrap replicate lines\n",
    "for i in range(100):\n",
    "    _ = plt.plot(x, bs_reps_slope[i] * x + bs_reps_int[i], \n",
    "                 color='red', alpha=0.2, linewidth=0.5)\n",
    "    \n",
    "# Update the plot\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9adb68-aaf1-40c2-92f5-d39853f8352a",
   "metadata": {},
   "source": [
    "### Hypothesis test: can this be by chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b82dc0-e5bd-4133-b502-167274ed4d39",
   "metadata": {},
   "source": [
    "##### Compute the observed Pearson correlation coefficient, storing it as rho.\n",
    "##### Initialize an array to store the 10,000 permutation replicates of rho using np.empty(). Name the array perm_reps_rho.\n",
    "##### Write a for loop to draw the permutation replicates.\n",
    "##### Scramble the lanes array using np.random.permutation().\n",
    "##### Compute the Pearson correlation coefficient between the scrambled lanes array and f_13. Store the result in perm_reps_rho.\n",
    "##### Compute and print the p-value. Take \"at least as extreme as\" to be that the Pearson correlation coefficient is greater than or equal to what was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0dc94-22e1-4828-93c2-c1e89aa50a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute observed correlation: rho\n",
    "rho = dcst.pearson_r(lanes, f_13)\n",
    " \n",
    "# Initialize permutation reps: perm_reps_rho\n",
    "perm_reps_rho = np.empty(10000)\n",
    " \n",
    "# Make permutation reps\n",
    "for i in range(10000):\n",
    "    # Scramble the lanes array: scrambled_lanes\n",
    "    scrambled_lanes = np.random.permutation(lanes)\n",
    "     \n",
    "    # Compute the Pearson correlation coefficient\n",
    "    perm_reps_rho[i] = dcst.pearson_r(scrambled_lanes, f_13)\n",
    "     \n",
    "# Compute and print p-value\n",
    "p_val = np.sum(perm_reps_rho >= rho) / 10000\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df15ded-eee1-4969-beba-ee08641645c7",
   "metadata": {},
   "source": [
    "### Parkfield earthquake magnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db9bad1-857e-48de-9d98-0660e4264d9a",
   "metadata": {},
   "source": [
    "##### Generate a plot of the ECDF in one line, using the *dcst.ecdf() approach describe above. Call plt.plot() with the marker='.' and linestyle='none' keyword arguments as usual.\n",
    "##### Label the x-axis 'magnitude', y-axis 'ECDF', and show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bd017-72b6-432d-ab2e-7afacbc36767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the plot\n",
    "plt.plot(*dcst.ecdf(mags), marker='.', linestyle='none')\n",
    " \n",
    "# Label axes and show plot\n",
    "plt.xlabel('magnitude')\n",
    "plt.ylabel('ECDF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa9c63-8d94-4ea2-b7d2-652f00fbfeda",
   "metadata": {},
   "source": [
    "### Computing the b-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1842c10a-2882-43f7-b44a-ec796b0c6181",
   "metadata": {},
   "source": [
    "##### Define a function with signature b_value(mags, mt, perc=[2.5, 97.5], n_reps=None) that does the following:\n",
    "##### Slice magnitudes out of mags at and above the completeness threshold mt using Boolean indexing. Store the result in the variable m.\n",
    "##### Compute the best estimate of the b-value. Remember, the best estimate for the b-value is b = (m - mt)·ln(10). Store the result in the variable b.if n_reps is not None, do the following.\n",
    "##### Draw n_reps bootstrap replicates of the mean of m. Store the result in the variable m_bs_reps.\n",
    "##### Convert the bootstrap replicates of the mean of m to replicates of the b-value. Store the result in b_bs_reps.\n",
    "##### Compute the confidence interval from the bootstrap replicates of the b-value. Store the result in conf_int.\n",
    "##### Return b and conf_int, or just b if n_reps is None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f7170-f049-4be4-bc94-89a18e11bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_value(mags, mt, perc=[2.5, 97.5], n_reps=None):\n",
    "    \"\"\"Compute the b-value and optionally its confidence interval.\"\"\"\n",
    "    # Extract magnitudes above completeness threshold: m\n",
    "    m = mags[mags >= mt]\n",
    " \n",
    "    # Compute b-value: b\n",
    "    b = (np.mean(m) - mt) * np.log(10)\n",
    " \n",
    "    # Draw bootstrap replicates\n",
    "    if n_reps is None:\n",
    "        return b\n",
    "    else:\n",
    "        m_bs_reps = dcst.draw_bs_reps(m, np.mean, size=n_reps)\n",
    " \n",
    "        # Compute b-value from replicates: b_bs_reps\n",
    "        b_bs_reps = (m_bs_reps - mt) * np.log(10)\n",
    " \n",
    "        # Compute confidence interval: conf_int\n",
    "        conf_int = np.percentile(b_bs_reps, perc)\n",
    "     \n",
    "        return b, conf_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ceee4-0051-4c29-b658-614966aa1d9e",
   "metadata": {},
   "source": [
    "### The b-value for Parkfield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a965da52-2d9d-4b71-8a50-d9b29fd1d277",
   "metadata": {},
   "source": [
    "##### Compute the b-value and the 95% confidence interval using your b_value() function. Use 10,000 bootstrap replicates.\n",
    "##### Use np.random.exponential() to draw 100,000 samples from the theoretical distribution. The mean for the distribution is b/np.log(10), and you need to add mt to your samples to appropriately handle the location parameter. Store the result in m_theor.\n",
    "##### Plot the ECDF of m_theor as a line.\n",
    "##### Plot the ECDF of all magnitudes above mt as dots.\n",
    "##### Hit 'Submit Answer' to display the plot and print the b-value and confidence interval to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38facad7-e2cd-461e-96ec-a500f2001693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute b-value and confidence interval\n",
    "b, conf_int = b_value(mags, mt, perc=[2.5, 97.5], n_reps=10000)\n",
    " \n",
    "# Generate samples to for theoretical ECDF\n",
    "m_theor = np.random.exponential(b/np.log(10), size=100000) + mt\n",
    " \n",
    "# Plot the theoretical CDF\n",
    "_ = plt.plot(*dcst.ecdf(m_theor))\n",
    " \n",
    "# Plot the ECDF (slicing mags >= mt)\n",
    "_ = plt.plot(*dcst.ecdf(mags[mags >= mt]), marker='.', linestyle='none')\n",
    " \n",
    "# Pretty up and show the plot\n",
    "_ = plt.xlabel('magnitude')\n",
    "_ = plt.ylabel('ECDF')\n",
    "_ = plt.xlim(2.8, 6.2)\n",
    "plt.show()\n",
    "\n",
    "# Report the results\n",
    "print(\"\"\"\n",
    "b-value: {0:.2f}\n",
    "95% conf int: [{1:.2f}, {2:.2f}]\"\"\".format(b, *conf_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bf940-790c-49e0-b243-f44de53efe11",
   "metadata": {},
   "source": [
    "### Interearthquake time estimates for Parkfield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b849ca-ec6b-4c06-90e9-70f41ad56325",
   "metadata": {},
   "source": [
    "##### Compute the mean interearthquake time and store it as mean_time_gap. The time gaps between the major earthquakes, in units of years, are stored in time_gap.\n",
    "##### Compute the standard deviation of the interearthquake times and store it as std_time_gap.\n",
    "##### Use np.random.exponential() to draw 10,000 samples out of an Exponential distribution with the appropriate mean. Store them in the variable time_gap_exp.\n",
    "##### Use np.random.normal() to draw 10,000 samples out of a Normal distribution with the appropriate mean and standard deviation. Store them in the variable time_gap_norm.\n",
    "##### Plot the theoretical CDFs in one line each, using the *dcst.ecdf() approach introduced earlier in this chapter.\n",
    "##### Plot the ECDF using the formal=True, min_x=-10, and max_x=50 keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5c6c04-5d40-4dbd-abf6-b2c932c8d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean time gap: mean_time_gap\n",
    "mean_time_gap = np.mean(time_gap)\n",
    " \n",
    "# Standard deviation of the time gap: std_time_gap\n",
    "std_time_gap = np.std(time_gap)\n",
    " \n",
    "# Generate theoretical Exponential distribution of timings: time_gap_exp\n",
    "time_gap_exp = np.random.exponential(scale=mean_time_gap, size=10000)\n",
    " \n",
    "# Generate theoretical Normal distribution of timings: time_gap_norm\n",
    "time_gap_norm = np.random.normal(loc=mean_time_gap, scale=std_time_gap, size=10000)\n",
    " \n",
    "# Plot theoretical CDFs\n",
    "_ = plt.plot(*dcst.ecdf(time_gap_exp))\n",
    "_ = plt.plot(*dcst.ecdf(time_gap_norm))\n",
    " \n",
    "# Plot Parkfield ECDF\n",
    "_ = plt.plot(*dcst.ecdf(time_gap, formal=True, min_x=-10, max_x=50))\n",
    " \n",
    "# Add legend\n",
    "_ = plt.legend(('Exp.', 'Norm.'), loc='upper left')\n",
    " \n",
    "# Label axes, set limits and show plot\n",
    "_ = plt.xlabel('time gap (years)')\n",
    "_ = plt.ylabel('ECDF')\n",
    "_ = plt.xlim(-10, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21b620-2464-4962-8e62-55b6adba1f48",
   "metadata": {},
   "source": [
    "### When will the next big Parkfield quake be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f27845d-190e-4d87-94e4-aa2710f23ba1",
   "metadata": {},
   "source": [
    "##### Draw 100,000 sample from an Exponential distribution with a mean given by mean_time_gap. Store the result in exp_samples.\n",
    "##### Draw 100,000 sample from a Normal distribution with a mean given by mean_time_gap and standard deviation given by std_time_gap. Store the result in norm_samples.\n",
    "##### Because there has not been a Parkfield earthquake as of today, slice out samples that are greater than today - last_quake, where I have stored the decimal year of today as today, and last_quake = 2004.74, the decimal year of the last Parkfield earthquake. Overwrite the respective exp_samples and norm_samples variables with these sliced arrays.\n",
    "##### Use np.percentile() to compute the 95% confidence interval for when the next Parkfield earthquake will be. In the same function call, you can also compute the median by including the 50th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25cf4a-ab3a-4056-85c1-392094c09807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw samples from the Exponential distribution: exp_samples\n",
    "exp_samples = np.random.exponential(scale=mean_time_gap, size=100000)\n",
    " \n",
    "# Draw samples from the Normal distribution: norm_samples\n",
    "norm_samples = np.random.normal(loc=mean_time_gap, scale=std_time_gap, size=100000)\n",
    " \n",
    "# No earthquake as of today, so only keep samples that are long enough\n",
    "exp_samples = exp_samples[exp_samples > today - last_quake]\n",
    "norm_samples = norm_samples[norm_samples > today - last_quake]\n",
    " \n",
    "# Compute the confidence intervals with medians\n",
    "conf_int_exp = np.percentile(exp_samples, [2.5, 50, 97.5]) + last_quake\n",
    "conf_int_norm = np.percentile(norm_samples, [2.5, 50, 97.5]) + last_quake\n",
    " \n",
    "# Print the results\n",
    "print('Exponential:', conf_int_exp)\n",
    "print('     Normal:', conf_int_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553f0c7-c259-4fcd-83e6-d1766769fd27",
   "metadata": {},
   "source": [
    "### Computing the K-S statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c26e4-4dd2-466d-99c0-670c0cd77287",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Compute the values of the convex corners of the formal ECDF for data1 using dcst.ecdf(). Store the results in the variables x and y.\n",
    "##### Use dcst.ecdf_formal() to compute the values of the theoretical CDF, determined from data2, at the convex corners x. Store the result in the variable cdf.\n",
    "##### Compute the distances between the concave corners of the formal ECDF and the theoretical CDF. Store the result as D_top.\n",
    "##### Compute the distance between the convex corners of the formal ECDF and the theoretical CDF. Note that you will need to subtract 1/len(data1) from y to get the y-value at the convex corner. Store the result in D_bottom.\n",
    "##### Return the K-S statistic as the maximum of all entries in D_top and D_bottom. You can pass D_top and D_bottom together as a tuple to np.max() to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7db9e-6863-49a1-9807-3fe4146b0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_stat(data1, data2):\n",
    "    # Compute ECDF from data: x, y\n",
    "    x, y = dcst.ecdf(data1)\n",
    "     \n",
    "    # Compute corresponding values of the target CDF\n",
    "    cdf = dcst.ecdf_formal(x, data2)\n",
    " \n",
    "    # Compute distances between concave corners and CDF\n",
    "    D_top = y - cdf\n",
    " \n",
    "    # Compute distance between convex corners and CDF\n",
    "    D_bottom = cdf - y + 1/len(data1)\n",
    " \n",
    "    return np.max((D_top, D_bottom))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ff06a-fe6e-4df1-b91d-02f620ff50b5",
   "metadata": {},
   "source": [
    "### Drawing K-S replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd2049-27c0-4892-9ae4-c0e099ed37d9",
   "metadata": {},
   "source": [
    "##### Write a function with signature draw_ks_reps(n, f, args=(), size=10000, n_reps=10000) that does the following.\n",
    "##### Generate size samples from the target distribution f. Remember, to pass the args into the sampling function, you should use the f(*args, size=size) construction. Store the result as x_f.\n",
    "##### Initialize the replicates array, reps, as an empty array with n_reps entries.\n",
    "##### Write a for loop to do the following n_reps times.\n",
    "##### Draw n samples from f. Again, use *args in your function call. Store the result in the variable x_samp.\n",
    "##### Compute the K-S statistic using dcst.ks_stat(), which is the function you wrote in the previous exercise, conveniently stored in the dcst module. Store the result in the reps array.\n",
    "##### Return the array reps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5b0ab-f408-4fed-bfad-a1e65d863687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ks_reps(n, f, args=(), size=10000, n_reps=10000):\n",
    "    # Generate samples from target distribution\n",
    "    x_f = f(*args, size=size)\n",
    "     \n",
    "    # Initialize K-S replicates\n",
    "    reps = np.empty(n_reps)\n",
    "     \n",
    "    # Draw replicates\n",
    "    for i in range(n_reps):\n",
    "        # Draw samples for comparison\n",
    "        x_samp = f(*args, size=n)\n",
    "         \n",
    "        # Compute K-S statistic\n",
    "        reps[i] = dcst.ks_stat(x_samp, x_f)\n",
    " \n",
    "    return reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2619937-deb3-41d2-a17b-783fca5ca456",
   "metadata": {},
   "source": [
    "### The K-S test for Exponentiality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1d508-efe4-4edd-abd6-cd89bf010704",
   "metadata": {},
   "source": [
    "##### Draw 10,000 replicates from the Exponential distribution using np.random.exponential(). The mean time gap between earthquakes is stored as mean_time_gap, which you computed in a previous exercise. Store the result in x_f.\n",
    "##### Use these samples, x_f, along with the actual time gaps, stored in time_gap, to compute the Kolmogorov-Smirnov statistic using dcst.ks_stat().\n",
    "##### Use the function you wrote in the last exercise, now conveniently stored as dcst.draw_ks_reps() to draw 10,000 K-S replicates from the Exponential distribution. Use the size=10000 keyword argument for drawing out of the target Exponential distribution. Store the replicates as reps.\n",
    "##### Compute and print the p-value. Remember that \"at least as extreme as\" is defined in this case as the test statistic under the null hypothesis being greater than or equal to what was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fc4bb-ef08-4b27-8e24-54806cf51445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw target distribution: x_f\n",
    "x_f = np.random.exponential(scale=mean_time_gap, size=10000)\n",
    " \n",
    "# Compute K-S stat: d\n",
    "d = dcst.ks_stat(x_f, time_gap)\n",
    " \n",
    "# Draw K-S replicates: reps\n",
    "reps = dcst.draw_ks_reps(len(time_gap), np.random.exponential, \n",
    "                         args=(mean_time_gap,), size=10000, n_reps=10000)\n",
    " \n",
    "# Compute and print p-value\n",
    "p_val = np.sum(reps >= d) / 10000\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20aa105-7201-4c34-8ff0-850c86bb77d2",
   "metadata": {},
   "source": [
    "### EDA: Plotting earthquakes over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568179b-ee16-4e29-9bdc-78c53909683d",
   "metadata": {},
   "source": [
    "##### Plot the magnitude (mags) versus time (time) using plt.plot() with keyword arguments marker='.' and linestyle='none'. Also use the keyword argument alpha=0.1 to make the points transparent to better visualize overlapping points.\n",
    "##### Label the x-axis 'time (year)', y-axis 'magnitude', and show the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f523984-6d0a-4e9b-a0d3-06c1b6b69bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time vs. magnitude\n",
    "plt.plot(time, mags, marker='.', linestyle='none', alpha=0.1)\n",
    " \n",
    "# Label axes and show the plot\n",
    "plt.xlabel('time (year)')\n",
    "plt.ylabel('magnitude')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d9962-7413-4acf-8b54-a69308c2f21e",
   "metadata": {},
   "source": [
    "### Estimates of the mean interearthquake times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3864276-672b-4494-8dba-cfd89951c885",
   "metadata": {},
   "source": [
    "##### Compute the mean interearthquake time for pre- (dt_pre) and post-2010 (dt_post).\n",
    "##### Draw 10,000 bootstrap replicates of the mean for the pre- and post-2010 datasets.\n",
    "##### Use np.percentile() to compute the 95% confidence interval of the mean for both datasets.\n",
    "##### Hit 'Submit Answer' to print the results to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1a247-2383-4982-bf11-d3a0a4c29680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean interearthquake time\n",
    "mean_dt_pre = np.mean(dt_pre)\n",
    "mean_dt_post = np.mean(dt_post)\n",
    " \n",
    "# Draw 10,000 bootstrap replicates of the mean\n",
    "bs_reps_pre = dcst.draw_bs_reps(dt_pre, np.mean, size=10000)\n",
    "bs_reps_post = dcst.draw_bs_reps(dt_post, np.mean, size=10000)\n",
    " \n",
    "# Compute the confidence interval\n",
    "conf_int_pre = np.percentile(bs_reps_pre, [2.5, 97.5])\n",
    "conf_int_post = np.percentile(bs_reps_post, [2.5, 97.5])\n",
    "# Print the results\n",
    "print(\"\"\"1980 through 2009\n",
    "mean time gap: {0:.2f} days\n",
    "95% conf int: [{1:.2f}, {2:.2f}] days\"\"\".format(mean_dt_pre, *conf_int_pre))\n",
    "\n",
    "print(\"\"\"\n",
    "2010 through mid-2017\n",
    "mean time gap: {0:.2f} days\n",
    "95% conf int: [{1:.2f}, {2:.2f}] days\"\"\".format(mean_dt_post, *conf_int_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d0c2bc-ca93-47d5-9cba-4ccc4926ac54",
   "metadata": {},
   "source": [
    "### Hypothesis test: did earthquake frequency change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1288aca-5357-45fd-9f74-d12f59b95764",
   "metadata": {},
   "source": [
    "##### Compute the observed test statistic. The variables mean_dt_pre and mean_dt_post from previous exercises are in your namespace.\n",
    "##### Shift the post-2010 data to have the same mean as the pre-2010 data. Store the result as dt_post_shift.\n",
    "##### Draw 10,000 bootstrap replicates each of mean of dt_pre and dt_post_shift. Store the respective results in bs_reps_pre and bs_reps_post.\n",
    "##### Compute replicates of difference of means by subtracting bs_reps_post from bs_reps_pre.\n",
    "##### Compute and print the p-value. Consider \"at least as extreme as\" to be that the test statistic is greater than or equal to what was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc490c-a9a0-4deb-a1d0-b4e25f93e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the observed test statistic\n",
    "mean_dt_diff = mean_dt_pre - mean_dt_post\n",
    " \n",
    "# Shift the post-2010 data to have the same mean as the pre-2010 data\n",
    "dt_post_shift = dt_post - mean_dt_post + mean_dt_pre\n",
    " \n",
    "# Compute 10,000 bootstrap replicates from arrays\n",
    "bs_reps_pre = dcst.draw_bs_reps(dt_pre, np.mean, size=10000)\n",
    "bs_reps_post = dcst.draw_bs_reps(dt_post_shift, np.mean, size=10000)\n",
    " \n",
    "# Get replicates of difference of means\n",
    "bs_reps = bs_reps_pre - bs_reps_post\n",
    " \n",
    "# Compute and print the p-value\n",
    "p_val = np.sum(bs_reps >= mean_dt_diff) / 10000\n",
    "print('p =', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16683a50-13c9-426c-b1cc-adf1eefe0374",
   "metadata": {},
   "source": [
    "### EDA: Comparing magnitudes before and after 2010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6ebf45-7d18-4c84-90f4-8751bcc408d0",
   "metadata": {},
   "source": [
    "##### Use Boolean indexing to slice out the magnitudes of all earthquakes before 2010 and store the result in mags_pre. Similarly, generate a numpy array mags_post that has all magnitudes of earthquakes in and after 2010.\n",
    "##### Use plt.plot() with a *dcst.ecdf(____) argument to make ECDFs for pre- and post- 2010 earthquake magnitudes. Remember to specify arguments for the marker and linestyle parameters.\n",
    "##### Hit 'Submit Answer' to view the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c465c8-bdd2-4367-91d5-5cb9bdc4ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get magnitudes before and after 2010\n",
    "mags_pre = mags[time < 2010]\n",
    "mags_post = mags[time >= 2010]\n",
    " \n",
    "# Generate ECDFs\n",
    "plt.plot(*dcst.ecdf(mags_pre), marker='.', linestyle='none')\n",
    "plt.plot(*dcst.ecdf(mags_post), marker='.', linestyle='none')\n",
    " \n",
    " \n",
    "# Label axes and show plot\n",
    "_ = plt.xlabel('magnitude')\n",
    "_ = plt.ylabel('ECDF')\n",
    "plt.legend(('1980 though 2009', '2010 through mid-2017'), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac250a-9876-4a34-9847-9e3ff6c7d675",
   "metadata": {},
   "source": [
    "### Quantification of the b-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda372fa-3fcc-4265-86cd-50d1d456a97c",
   "metadata": {},
   "source": [
    "##### Compute the b-value and 95% confidence interval for earthquakes from 1980 through 2009 using 10,000 bootstrap replicates.\n",
    "##### Compute the b-value and 95% confidence interval for earthquakes from 2010 through mid-2017 using 10,000 bootstrap replicates.\n",
    "##### Hit 'Submit Answer' to print the results to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3b261-f92a-46bc-8c5f-59f8315a269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute b-value and confidence interval for pre-2010\n",
    "b_pre, conf_int_pre = b_value(mags_pre, mt, perc=[2.5, 97.5], n_reps=10000)\n",
    "\n",
    "# Compute b-value and confidence interval for post-2010\n",
    "b_post, conf_int_post = b_value(mags_post, mt, perc=[2.5, 97.5], n_reps=10000)\n",
    "\n",
    "# Report the results\n",
    "print(\"\"\"\n",
    "1980 through 2009\n",
    "b-value: {0:.2f}\n",
    "95% conf int: [{1:.2f}, {2:.2f}]\n",
    "\n",
    "2010 through mid-2017\n",
    "b-value: {3:.2f}\n",
    "95% conf int: [{4:.2f}, {5:.2f}]\n",
    "\"\"\".format(b_pre, *conf_int_pre, b_post, *conf_int_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb95fb70-0166-42ee-8462-2a38fd7ec15c",
   "metadata": {},
   "source": [
    "### Hypothesis test: are the b-values different?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e0343-dd82-4f0f-9835-e5a3158c49f1",
   "metadata": {},
   "source": [
    "##### Slice out the magnitudes of earthquakes before 2010 that have a magnitude above (or equal) the completeness threshold and overwrite mags_pre with the result. Do the same for mags_post.\n",
    "##### Compute the observed difference in mean magnitudes, subtracting the magnitudes of pre-2010 earthquakes from those of post-2010 earthquakes.\n",
    "##### Generate 10,000 permutation replicates using dcst.draw_perm_reps(). Use dcst.diff_of_means as the argument for func.\n",
    "##### Compute and print the p-value taking \"at least as extreme as\" to mean that the test statistic is smaller than what was observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bfde02-8de6-4a68-9a20-45d3058d71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only magnitudes above completeness threshold\n",
    "mags_pre = mags_pre[mags_pre >= mt]\n",
    "mags_post = mags_post[mags_post >= mt]\n",
    " \n",
    "# Observed difference in mean magnitudes: diff_obs\n",
    "diff_obs = np.mean(mags_post) - np.mean(mags_pre)\n",
    " \n",
    "# Generate permutation replicates: perm_reps\n",
    "perm_reps = dcst.draw_perm_reps(mags_post, mags_pre, dcst.diff_of_means, size=10000)\n",
    " \n",
    "# Compute and print p-value\n",
    "p_val = np.sum(perm_reps < diff_obs) / 10000\n",
    "print('p =', p_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
