{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-DSnrgcyvUo"
   },
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SbJ4haGyvUp"
   },
   "source": [
    "In the code below, we create a single input array (which could be considered a single greyscale image) and pass that through a *max pooling* layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M3gd5dmmyvUp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlykcCdqyvUq",
    "outputId": "38a9d10b-59c6-49d9-ca29-bcb47fc9573c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9  1 11 12]\n",
      " [13 14 15 16]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 6],\n",
       "         [ 8]],\n",
       "\n",
       "        [[14],\n",
       "         [16]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4],       # create a single 2-dimensional image\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 1, 11, 12],\n",
    "              [13, 14, 15, 16]])\n",
    "print(x)\n",
    "\n",
    "x = x.reshape([1, 4, 4, 1])  # reshape to (batch_size, h, w, n_c) since the max pooling layer expects arrays with these dimensions\n",
    "\n",
    "max_pool_2d = MaxPooling2D(pool_size=(2, 2),  # define the max pooling layer\n",
    "                           strides=2)\n",
    "\n",
    "max_pool_2d(x).numpy() # pass the input image through the max pooling layer to get our output (.numpy converts from tensor to an array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "of5b8VFvyvUq"
   },
   "source": [
    "Note that if you change the dimensions of `x` you will need to change the code `x = x.reshape()` to the corresponding values or else you will get an error.\n",
    "\n",
    " - Change the values in `x`, calculate by hand what the output should be and then verify by running the code.\n",
    " - Change the `strides` to 1, calculate by hand what the output should be and then verify by running the code.\n",
    " - Change the `pool_size` to `(3, 3)` and run the code. Are the output dimensions what you would expect? What is happening?\n",
    " - Explore some of the other 2D pooling layers found in the [Keras documentation](https://keras.io/api/layers/pooling_layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7_DzG0dyvUq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "az3McNBhyvUq"
   },
   "source": [
    "## Exploring Dimensions\n",
    "\n",
    "Assuming the input images have a dimesion of 32x32x3 and that there are 6 classes, create the following convolutional network structures and view `.summary()` for each:\n",
    "\n",
    "- (convolution / pooling) x n +  (1 fully-connected layer) + (output layer)\n",
    "    - keep increasing `n` until the output shape just before the `Flatten` layer is `(_, <10, <10, _)`\n",
    "- (convolution / convolution / pooling) x n + (1 fully-connected layer) + (output layer)\n",
    "    - keep increasing `n` until the output shape just before the `Flatten` layer is `(_, <10, <10, _)`\n",
    "\n",
    "For all networks, the number of filters should increase as you go deeper into the network (number of filters usually equal $2^m$) and the height and width should decrease.\n",
    "\n",
    "Use the `name` argument to name each layer but organized into blocks, where (convolution / pooling) would be a single block and (convolution / convolution / pooling) would be a single block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRaQvAzHyvUq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSgx0y_YyvUq"
   },
   "source": [
    "Fill in the table below using the information in the `.summary()` output for each network created above:\n",
    "\n",
    "|Convolutional layers | Pooling layers | Trainable parameters | Output shape before `Flatten` |\n",
    "|:-:|:-:|:-:|:-:|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2VP7YpdyvUr"
   },
   "source": [
    "## Pre-Trained Models\n",
    "\n",
    "From [Keras Applications](https://keras.io/api/applications/):\n",
    " - import the **VGG16** network\n",
    " - view its structure\n",
    " - compare the depth and number of parameters to your networks from above\n",
    " - what data has this network been trained on? How many images are in this dataset? How many classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpIGc9j-yvUr",
    "outputId": "8619368b-9900-4939-f685-4b5e31521b7f"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(include_top=False,\n",
    "                  weights=\"imagenet\", #using the weights of the imagenet dataset\n",
    "                  input_shape=(244, 244, 3)) #using the infos of the imagenet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 244, 244, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 244, 244, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 122, 122, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 122, 122, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 122, 122, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 61, 61, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 61, 61, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 61, 61, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 30, 30, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 30, 30, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 30, 30, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 14714688 (56.13 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3q_WIUCdyvUr"
   },
   "source": [
    "## Keras's functional API\n",
    "\n",
    "To use these pre-trained networks, we will need to use the *functional* instead of the *sequential* API for building networks in Keras. Even if you don't use a pre-trained network, the functional API is more flexible so it is good to understand the basics of how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kU_x8boRyvUr"
   },
   "source": [
    "### Fully-Connected Model\n",
    "\n",
    "Using the [Keras documentation](https://keras.io/guides/functional_api/), create and train a fully-connected model for the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXyMNqLCyvUr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asP7rLHuyvUr"
   },
   "source": [
    "### Convolutional Models\n",
    "\n",
    "Now use the functional API to create and train a convolutional model for the MNIST data. Follow one of the patterns from the **Exploring Dimensions** section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXdQqMl6yvUr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnI58juxyvUr"
   },
   "source": [
    "Now create a small convolutional neural network for the **Fashion MNIST** data (comes with Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1L4Eu1xyvUr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYCrHB5QyvUr"
   },
   "source": [
    "### Convolutional Model with Scaling\n",
    "\n",
    "Now add a [rescaling](https://keras.io/api/layers/preprocessing_layers/image_preprocessing/rescaling/) layer to the model you created above for the fashion MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Owdhjqs3yvUr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXn_KCP2yvUr"
   },
   "source": [
    "### Convolutional Model with Scaling and Data Augmentation\n",
    "\n",
    "Now add data augmentation to the model you created above for the fashion MNIST data. This model will have both scaling and data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hBHkLEFQyvUr"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.05),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomTranslation(\n",
    "        height_factor=0.1,\n",
    "        width_factor=0.2,\n",
    "        fill_mode=\"nearest\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oKVUpoF8CvKl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x2403b07e0a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
